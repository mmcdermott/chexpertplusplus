{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "import itertools, os, time, pickle, pandas as pd, matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from chexpert_approximator.data_processor import *\n",
    "from chexpert_approximator.run_classifier import *\n",
    "\n",
    "from chexpert_approximator.reload_and_get_logits import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't display MIMIC-CXR Output:\n",
    "\n",
    "DO_BLIND = True\n",
    "def blind_display(df):\n",
    "    if DO_BLIND:     \n",
    "        df = df.copy()\n",
    "        index_levels = df.index.names\n",
    "        df.reset_index('rad_id', inplace=True)\n",
    "        df['rad_id'] = [0 for _ in df['rad_id']]\n",
    "        df.set_index('rad_id', append=True, inplace=True)\n",
    "        df = df.reorder_levels(index_levels, axis=0)\n",
    "\n",
    "        for c in df.columns:\n",
    "            if pd.api.types.is_string_dtype(df[c]): df[c] = ['SAMPLE' for _ in df[c]]\n",
    "            else: df[c] = np.NaN\n",
    "\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/scratch/chexpert_approximator/processed_data/' # INSERT YOUR DATA DIR HERE!\n",
    "# DATA MUST BE STORED IN A FILE `inputs.hdf` under key `with_folds`.\n",
    "INPUT_PATH, INPUT_KEY = os.path.join(DATA_DIR, 'inputs.hdf'), 'with_folds'\n",
    "\n",
    "# YOUR CLINICAL BERT MODEL GOES HERE\n",
    "BERT_MODEL_PATH = (\n",
    "    '/data/medg/misc/clinical_BERT/cliniBERT/models/pretrained_bert_tf/bert_pretrain_output_all_notes_300000/'\n",
    ")\n",
    "\n",
    "# THIS IS WHERE YOUR PRE-TRAINED CHEXPERT++ MODEL LIVES\n",
    "PRETRAINED_CXPPP_PATH = '/crimea/mmd/CheXpert_Approximator/out/run_1'\n",
    "\n",
    "# DON'T MODIFY THESE\n",
    "FOLD = 'Fold'\n",
    "\n",
    "KEY = {\n",
    "    0: 'No Mention',\n",
    "    1: 'Uncertain Mention',\n",
    "    2: 'Negative Mention',\n",
    "    3: 'Positive Mention',\n",
    "}\n",
    "INV_KEY = {v: k for k, v in KEY.items()}\n",
    "SENT_NUM = 'Sentence Number'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.read_hdf(INPUT_PATH, INPUT_KEY)\n",
    "label_cols = [col for col in inputs.index.names if col not in ('rad_id', FOLD)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_num = pd.Series(index=inputs.index, data=1)\n",
    "sentence_num = sentence_num.groupby('rad_id').cumsum()\n",
    "\n",
    "inputs[SENT_NUM] = sentence_num\n",
    "inputs.set_index(SENT_NUM, append=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 753611 sentences with 14 labels: ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Lesion', 'Airspace Opacity', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rad_id</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Airspace Opacity</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Sentence Number</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Positive Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>6</th>\n",
       "      <th>1</th>\n",
       "      <td>SAMPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>6</th>\n",
       "      <th>2</th>\n",
       "      <td>SAMPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Mention</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Mention</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Mention</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Mention</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Mention</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Mention</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Mention</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Mention</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Mention</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Mention</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Mention</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Mention</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Mention</th>\n",
       "      <th>6</th>\n",
       "      <th>3</th>\n",
       "      <td>SAMPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <td>SAMPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>Positive Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>No Mention</th>\n",
       "      <th>4</th>\n",
       "      <th>2</th>\n",
       "      <td>SAMPLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                         sentence\n",
       "rad_id No Finding       Enlarged Cardiomediastinum Cardiomegaly Lung Lesion Airspace Opacity Edema      Consolidation Pneumonia  Atelectasis Pneumothorax Pleural Effusion Pleural Other Fracture   Support Devices Fold Sentence Number         \n",
       "0      Positive Mention No Mention                 No Mention   No Mention  No Mention       No Mention No Mention    No Mention No Mention  No Mention   No Mention       No Mention    No Mention No Mention      6    1                 SAMPLE\n",
       "                        Negative Mention           No Mention   No Mention  No Mention       No Mention No Mention    No Mention No Mention  No Mention   No Mention       No Mention    No Mention No Mention      6    2                 SAMPLE\n",
       "                        No Mention                 No Mention   No Mention  No Mention       No Mention No Mention    No Mention No Mention  No Mention   No Mention       No Mention    No Mention No Mention      6    3                 SAMPLE\n",
       "                                                                                                                                                                                                                    4    1                 SAMPLE\n",
       "       No Mention       No Mention                 No Mention   No Mention  Positive Mention No Mention No Mention    No Mention No Mention  No Mention   No Mention       No Mention    No Mention No Mention      4    2                 SAMPLE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Read %d sentences with %d labels: %s' % (len(inputs), len(label_cols), str(label_cols)))\n",
    "blind_display(inputs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['No Mention', 'Uncertain Mention', 'Positive Mention', 'Negative Mention']\n",
    "\n",
    "frequencies = inputs[[]].reset_index()[label_cols].agg(lambda x: Counter(x))\n",
    "frequencies = pd.DataFrame(\n",
    "    index=frequencies.index, columns=keys, data=[[c[k] for k in keys] for c in frequencies]\n",
    ")\n",
    "frequencies /= len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No Mention</th>\n",
       "      <th>Uncertain Mention</th>\n",
       "      <th>Positive Mention</th>\n",
       "      <th>Negative Mention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No Finding</th>\n",
       "      <td>0.335499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.664501</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <td>0.882995</td>\n",
       "      <td>0.023573</td>\n",
       "      <td>0.016118</td>\n",
       "      <td>0.077313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <td>0.905755</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.051581</td>\n",
       "      <td>0.037990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lung Lesion</th>\n",
       "      <td>0.990409</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.001265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Airspace Opacity</th>\n",
       "      <td>0.918940</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.069406</td>\n",
       "      <td>0.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edema</th>\n",
       "      <td>0.938679</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.033532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consolidation</th>\n",
       "      <td>0.928832</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.058551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumonia</th>\n",
       "      <td>0.966668</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.008836</td>\n",
       "      <td>0.011108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atelectasis</th>\n",
       "      <td>0.943740</td>\n",
       "      <td>0.007266</td>\n",
       "      <td>0.047652</td>\n",
       "      <td>0.001342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumothorax</th>\n",
       "      <td>0.865748</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.007625</td>\n",
       "      <td>0.124619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <td>0.838069</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>0.045286</td>\n",
       "      <td>0.110570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleural Other</th>\n",
       "      <td>0.995596</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fracture</th>\n",
       "      <td>0.986886</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.007721</td>\n",
       "      <td>0.004987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Devices</th>\n",
       "      <td>0.910220</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.082699</td>\n",
       "      <td>0.006619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            No Mention  Uncertain Mention  Positive Mention  \\\n",
       "No Finding                    0.335499           0.000000          0.664501   \n",
       "Enlarged Cardiomediastinum    0.882995           0.023573          0.016118   \n",
       "Cardiomegaly                  0.905755           0.004673          0.051581   \n",
       "Lung Lesion                   0.990409           0.000920          0.007407   \n",
       "Airspace Opacity              0.918940           0.004447          0.069406   \n",
       "Edema                         0.938679           0.010551          0.017238   \n",
       "Consolidation                 0.928832           0.005661          0.006956   \n",
       "Pneumonia                     0.966668           0.013388          0.008836   \n",
       "Atelectasis                   0.943740           0.007266          0.047652   \n",
       "Pneumothorax                  0.865748           0.002009          0.007625   \n",
       "Pleural Effusion              0.838069           0.006075          0.045286   \n",
       "Pleural Other                 0.995596           0.000820          0.003469   \n",
       "Fracture                      0.986886           0.000406          0.007721   \n",
       "Support Devices               0.910220           0.000462          0.082699   \n",
       "\n",
       "                            Negative Mention  \n",
       "No Finding                          0.000000  \n",
       "Enlarged Cardiomediastinum          0.077313  \n",
       "Cardiomegaly                        0.037990  \n",
       "Lung Lesion                         0.001265  \n",
       "Airspace Opacity                    0.007208  \n",
       "Edema                               0.033532  \n",
       "Consolidation                       0.058551  \n",
       "Pneumonia                           0.011108  \n",
       "Atelectasis                         0.001342  \n",
       "Pneumothorax                        0.124619  \n",
       "Pleural Effusion                    0.110570  \n",
       "Pleural Other                       0.000115  \n",
       "Fracture                            0.004987  \n",
       "Support Devices                     0.006619  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "## Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheXpertProcessor(DataProcessor):\n",
    "    def __init__(self, tuning_fold, held_out_fold):\n",
    "        super().__init__()\n",
    "        self.tuning_fold, self.held_out_fold = tuning_fold, held_out_fold\n",
    "    \n",
    "    \"\"\"Processor for the CheXpert approximator.\n",
    "    Honestly this is kind of silly, as it never stores internal state.\"\"\"\n",
    "    def get_train_examples(self, df): return self._create_examples(\n",
    "        df, set([f for f in range(K) if f not in (self.tuning_fold, self.held_out_fold)])\n",
    "    )\n",
    "    def get_dev_examples(self, df):   return self._create_examples(df, set([self.tuning_fold]))\n",
    "    def get_examples(self, df, folds=[]): return self._create_examples(df, set(folds))\n",
    "    \n",
    "    def get_labels(self): return {label: list(range(4)) for label in label_cols}\n",
    "\n",
    "    def _create_examples(self, df, folds):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        df = df[df.index.get_level_values(FOLD).isin(folds)]\n",
    "        lmap = {l: i for i, l in enumerate(df.index.names)}\n",
    "        \n",
    "        examples = []\n",
    "        for idx, r in df.iterrows():\n",
    "            labels = {l: INV_KEY[idx[lmap[l]]] for l in label_cols}\n",
    "            \n",
    "            examples.append(InputExample(\n",
    "                guid=str(idx[lmap['rad_id']]), text_a=r.sentence, text_b=None, label=labels\n",
    "            ))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = CheXpertProcessor(8, 9)\n",
    "# train_examples = processor.get_train_examples(inputs)\n",
    "# dev_examples = processor.get_dev_examples(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_8_sents = set(inputs[inputs.index.get_level_values(FOLD) == 8].sentence)\n",
    "folds_0_7_sents = set()\n",
    "for f in range(8):\n",
    "    folds_0_7_sents.update(inputs[inputs.index.get_level_values(FOLD) == f].sentence)\n",
    "restricted_fold_8_inputs = inputs[\n",
    "    (inputs.index.get_level_values(FOLD) == 8) & ~inputs.sentence.isin(folds_0_7_sents)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/medg/misc/clinical_BERT/cliniBERT/models/pretrained_bert_tf/bert_pretrain_output_all_notes_300000/\n",
      "Max Sequence Length: 95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea850f515154551bf22a0030b599e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=114, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.1032366114750243, 'eval_accuracy': 0.9981117935756904} 214.65615105628967\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model, logits, results = reload_and_get_logits(\n",
    "    restricted_fold_8_inputs,\n",
    "    bert_model      = BERT_MODEL_PATH,\n",
    "    processor       = processor,\n",
    "    task_dimensions = {l: 4 for l in label_cols},\n",
    "    output_dir      = PRETRAINED_CXPPP_PATH,\n",
    "    gpu             = '0,1,2,3',\n",
    "    seed            = 42,\n",
    "    do_lower_case   = False,\n",
    "    max_seq_length  = 128,\n",
    "    batch_size      = 256,\n",
    "    processor_args  = {'folds': [8]},\n",
    ")\n",
    "end = time.time()\n",
    "\n",
    "print(results, end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert_time = 2 + 57/60 + (7/60)/60 # in hours\n",
    "chexpertPP_time = (end - start) / (60**2) * 10 # in hours\n",
    "\n",
    "print(\n",
    "    \"Total time was %.2f v. %.2f (CXB takes %.2f %% as long)\" % (\n",
    "        chexpertPP_time, chexpert_time, (chexpertPP_time / chexpert_time) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits_dfs = {k: pd.DataFrame(\n",
    "    np.vstack(v), columns=[KEY[i] for i in range(4)],\n",
    "    index=inputs[inputs.index.get_level_values(FOLD).isin([8])].index\n",
    ") for k, v in logits.items()}\n",
    "\n",
    "for k, df in logits_dfs.items():\n",
    "    df.columns = pd.MultiIndex.from_tuples([(k, c) for c in df.columns], names=('Task', 'Label'))\n",
    "logits_df = pd.concat(logits_dfs.values(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Produced %d %d-dim Logits in %.2f min.\" % (logits_df.shape[0], logits_df.shape[1], 60*chexpertPP_time/10))\n",
    "blind_display(logits_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More detailed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrices = {}\n",
    "keys = [KEY[i] for i in range(4)]\n",
    "error_rates = {'Majority Class': [], 'chexpertPP': []}\n",
    "confusion_subarrays = []\n",
    "confusion_flattened_subarrays = []\n",
    "normalized_confusion_flattened_subarrays = []\n",
    "\n",
    "for i, task in enumerate(label_cols):\n",
    "    logits = logits_df[task]\n",
    "    labels = logits_df.index.get_level_values(task)\n",
    "    predictions = logits.idxmax(axis=1)\n",
    "    c = confusion_matrix(list(labels.values), list(predictions.values), labels=keys)\n",
    "    c = pd.DataFrame(c, index=['True %s' % l for l in keys], columns=['Predicted %s' % l for l in keys])\n",
    "    \n",
    "    overall_accuracy = c.values[np.diag_indices(4)].sum() / len(logits_df) * 100\n",
    "    mc_accuracy = frequencies.max(axis=1)[task] * 100\n",
    "    \n",
    "    error_rates['Majority Class'].append((100 - mc_accuracy))\n",
    "    error_rates['chexpertPP'].append((100 - overall_accuracy))\n",
    "    confusion_subarrays.append(\n",
    "        [np.NaN * np.ones((4, 4))] * i + [c.values] + [np.NaN * np.ones((4, 4))] * (len(label_cols) - i - 1)\n",
    "    )\n",
    "    confusion_flattened_subarrays.append(c.values)\n",
    "    normalized_confusion_flattened_subarrays.append(c.values / c.values.sum(axis=1, keepdims=True))\n",
    "    \n",
    "    print(\n",
    "        \"For %s, we obtain Accuracy %.2f%% (vs. majority class %.2f%%). Error rates %.2e %% vs. %.2e %%.\"\n",
    "        \"\" % (task, overall_accuracy, mc_accuracy, 100 - overall_accuracy, 100 - mc_accuracy)\n",
    "    )\n",
    "    display(c)\n",
    "    confusion_matrices[task] = c\n",
    "    \n",
    "error_rates = pd.DataFrame(error_rates, index=label_cols)\n",
    "global_confusion_matrix = np.block(confusion_subarrays)\n",
    "confusion_matrix_flattened = np.block(confusion_flattened_subarrays)\n",
    "normalized_confusion_matrix_flattened = np.block(normalized_confusion_flattened_subarrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax_raw, ax_log, ax_norm) = plt.subplots(nrows=3, ncols=1, sharex=False, figsize=(42, 40))\n",
    "fig.suptitle('Various Transformations of the Confusion Matrices for all Tasks', fontsize=64, y=0.9)\n",
    "\n",
    "logbase = 10\n",
    "\n",
    "for row, (ax, mat, title) in enumerate((\n",
    "    (ax_raw, confusion_matrix_flattened, 'Raw Counts'),\n",
    "    (ax_norm, normalized_confusion_matrix_flattened, 'True Label Normalized'),\n",
    "    (ax_log, np.log10(confusion_matrix_flattened), 'Log Scale'),\n",
    ")):\n",
    "    m_handle = ax.matshow(mat, cmap='Greys')\n",
    "    ax.set_yticks([i for i in range(len(keys))])\n",
    "    ax.set_yticklabels(keys, fontsize=40)\n",
    "    \n",
    "    if row == 0: ax.set_title(title, fontsize=54, pad=300)\n",
    "    else:\n",
    "        ax.set_title(title, fontsize=54)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(5)\n",
    "\n",
    "    # ax.grid(True, which='minor', axis='x')\n",
    "\n",
    "    for i, label in enumerate(label_cols):\n",
    "        ax.axvline(4*(i+1) - 0.5, 0, 1, linewidth=5, color='k')\n",
    "\n",
    "    # divider = make_axes_locatable(ax)\n",
    "    # cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar = plt.colorbar(mappable=m_handle, ax=ax, fraction=0.3, pad=0.02, orientation='horizontal')\n",
    "    cbar.ax.tick_params(labelsize=48)\n",
    "    if title.startswith('Log'):\n",
    "        old_ticks = [x for x in cbar.get_ticks()]\n",
    "        new_ticks = [int(logbase**x) for x in old_ticks]\n",
    "        cbar.set_ticks(old_ticks)\n",
    "#         cbar.set_ticklabels(['$e^{%d} ≈ %d$' % v for v in zip(old_ticks, new_ticks)])\n",
    "        cbar.set_ticklabels(new_ticks)\n",
    "    \n",
    "\n",
    "ax_raw.set_xticks([1.5 + 4*i for i in range(len(label_cols))])\n",
    "ax_raw.set_xticklabels(label_cols, fontsize=40, rotation=90)\n",
    "plt.subplots_adjust(hspace=-0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Check of misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_inputs = logits_df.copy()\n",
    "with_inputs['Sentence'] = inputs[inputs.index.get_level_values(FOLD).isin([8])].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_display(with_inputs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./misclassifications/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = with_inputs['Sentence']\n",
    "for task in label_cols:\n",
    "    labels = with_inputs.index.get_level_values(task)\n",
    "    predictions = with_inputs[task].idxmax(axis=1)\n",
    "    misclassified_samples = with_inputs[labels != predictions]\n",
    "    tuples = np.random.permutation(\n",
    "        list(zip(*(d[labels != predictions].values for d in (labels, predictions, sentences))))\n",
    "    )\n",
    "    \n",
    "    misclassifications_df = pd.DataFrame(tuples, columns=['Labeler A', 'Labeler B', 'Sentence'])\n",
    "    misclassifications_df.to_csv(os.path.join('./misclassifications', '%s.csv' % task))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
